{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Data Scientist'\n",
    "location = 'Seattle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_list = []\n",
    "\n",
    "for page_start in range(0, 1000, 100):  \n",
    "    url = f'https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Data%20Scientist&&location=location=New%20York%2C%20New%20York%2C%20United%20States&start={page_start}'\n",
    "    response = requests.get(url)\n",
    "    list_soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    page_jobs = list_soup.find_all(\"li\")\n",
    "\n",
    "    for job in page_jobs:\n",
    "        base_card_div = job.find(\"div\", {\"class\": \"base-card\"})\n",
    "        job_id = base_card_div.get(\"data-entity-urn\").split(\":\")[3]\n",
    "\n",
    "        job_url = f\"https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{job_id}\"\n",
    "        job_response = requests.get(job_url)\n",
    "        job_soup = BeautifulSoup(job_response.text, 'html.parser')\n",
    "        job_post = {}\n",
    "\n",
    "        try:\n",
    "            job_post[\"company_name\"] = job_soup.find(\"a\", {\"class\": \"topcard__org-name-link topcard__flavor--black-link\"}).text.strip()\n",
    "        except:\n",
    "            job_post[\"company_name\"] = None\n",
    "        try:\n",
    "            job_post[\"job_title\"] = job_soup.find(\"h2\", {\"class\": \"top-card-layout__title font-sans text-lg papabear:text-xl font-bold leading-open text-color-text mb-0 topcard__title\"}).text.strip()\n",
    "        except:\n",
    "            job_post[\"job_title\"] = None\n",
    "        try:\n",
    "            job_post[\"location\"] = job_soup.find(\"span\", {\"class\": \"topcard__flavor topcard__flavor--bullet\"}).text.strip()\n",
    "        except:\n",
    "            job_post[\"location\"] = None\n",
    "        try:\n",
    "            job_post[\"num_applicants\"] = job_soup.find(\"span\", {\"class\": \"posted-time-ago__text topcard__flavor--metadata\"}).text.strip()\n",
    "        except:\n",
    "            job_post[\"num_applicants\"] = None\n",
    "\n",
    "        job_list.append(job_post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        company_name                           job_title  \\\n",
      "0   Cardio Diagnostics Holdings Inc.          Data Scientist, HEOR & RWE   \n",
      "1                               None                                None   \n",
      "2                         VARITE INC                      Data Scientist   \n",
      "3                          Replicate           Machine Learning Engineer   \n",
      "4                   Caterpillar Inc.                      Data Scientist   \n",
      "..                               ...                                 ...   \n",
      "85                          BioSpace       Biologist - Neurodegeneration   \n",
      "86                 AAA Club Alliance           Machine Learning Engineer   \n",
      "87                              None                                None   \n",
      "88              Pinnacle Group, Inc.                   QA AI/ML Engineer   \n",
      "89                     Phoenix Cyber  Python Developer [Job ID 20240425]   \n",
      "\n",
      "             location num_applicants  \n",
      "0         Chicago, IL      1 day ago  \n",
      "1                None           None  \n",
      "2        Alhambra, CA           None  \n",
      "3   San Francisco, CA     1 week ago  \n",
      "4         Chicago, IL     2 days ago  \n",
      "..                ...            ...  \n",
      "85   Indianapolis, IN     2 days ago  \n",
      "86     Wilmington, DE     3 days ago  \n",
      "87               None           None  \n",
      "88      Cupertino, CA           None  \n",
      "89     Washington, DC      1 day ago  \n",
      "\n",
      "[90 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "jobs_df = pd.DataFrame(job_list)\n",
    "print(jobs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df = pd.DataFrame(job_list)\n",
    "jobs_df.to_csv('Data_Scientist_NY.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
